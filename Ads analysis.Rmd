---
title: "Ads Analysis"
author: "Prasad"
date: "May 8, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R

# Challenge Description:
We have data about users who hit our site: whether they converted or not as well as some of
their characteristics such as their country, the marketing channel, their age, whether they are
repeat users and the number of pages visited during that session (as a proxy for site
activity/time spent on site).

The task is to:

- Predict conversion rate
- Come up with recommendations for the product team and the marketing team to
- improve conversion rate

```{r ads}

```

## Data

Columns:

- country : user country based on the IP address
- age : user age. Self-reported at sign-in step
- new_user : whether the user created the account during this session or had already an account and simply came back to the site
- source : marketing channel source
- Ads: came to the site by clicking on an advertisement
- Seo: came to the site by clicking on search results
- Direct: came to the site by directly typing the URL on the browser
- total_pages_visited: number of total pages visited during the session. This is a proxy for time spent on site and engagement during the session.
- converted: this is our label. 1 means they converted within the session, 0 means they leftwithout buying anything. The company goal is to increase conversion rate: # conversions
/ total sessions.

```{r, message=FALSE, warning=FALSE,echo=TRUE}
#libraries needed
library(dplyr)
library(rpart)
library(ggplot2)
library(randomForest)

```

```{r , message=FALSE, warning=FALSE,echo=FALSE}
data <- read.csv('C:\\Study material for interviews\\R\\R project\\conversion_data.csv')
```

```{r , message=FALSE, warning=FALSE,echo=TRUE}

```
Let's check the structure of the data
```{r , message=FALSE, warning=FALSE,echo=TRUE}
head(data)
```

```{r , message=FALSE, warning=FALSE,echo=TRUE}

str(data)
```
```{r , message=FALSE, warning=FALSE,echo=TRUE}

```

```{r , message=FALSE, warning=FALSE,echo=TRUE}
summary(data)
```
Some initial observations:

- Large Chinese user base for a US based comapany
- Median age of users around 30 years
- Conversion rate is around 3%

Let's inverstigate max age which is 123:


```{r , message=FALSE, warning=FALSE,echo=TRUE}
sort(unique(data$age), decreasing = TRUE)

```
Let's find out how many users are of the age 123 and 11

```{r , message=FALSE, warning=FALSE,echo=TRUE}
subset(data, age > 79)

```

Since, there are only 2 records. Let's remove them from our analysis.

```{r , message=FALSE, warning=FALSE,echo=TRUE}
data <- subset(data, age <80)

```

Now let's explore the variables:

```{r , message=FALSE, warning=FALSE,echo=TRUE}
data_country = data %>%
group_by(country) %>%
summarise(conversion_rate = mean(converted))

ggplot(data = data_country, aes(x=country, y=conversion_rate)) +
  geom_bar(stat = "identity", aes(fill = country))

```

We observe that China has the lowest conversion rate. It will be interesting to explore the reasons for this further.

```{r , message=FALSE, warning=FALSE,echo=TRUE}

```
```{r , message=FALSE, warning=FALSE,echo=TRUE}
data_pages = data %>%
  group_by(total_pages_visited) %>%
  summarise(conversion_rate = mean(converted))

ggplot(data = data_pages, aes(x=total_pages_visited,y=conversion_rate))+
  geom_line()

```

This graph definitely shows that longer you spend time on the site, brighter are chances of conversion.


Let's see average user age by country
```{r , message=FALSE, warning=FALSE,echo=TRUE}
data_user = data %>%
  group_by(country) %>%
  summarize(age_by_country = mean(age))


ggplot(data = data_user, aes(x= country, y = age_by_country ))+
  geom_bar(stat = "identity", aes(fill= country) )

```
This graph shows that user all across the world are on an average 30 years of age.

### Machine Learning

Let's build a model to predict the conversion. The output is binary and we care about insights to give the product and marketing teams.

I am going to pick Random Forest for predicting the conversion rate. I used this algorithm beacuse:

- It usually requires very little time to optimize it (its default params are often close to the best ones) 
- It is strong with outliers, irrelevant variables, continuous and discrete variables

I will use the random forest to predict conversion, then I will use its partial dependence plots and variable importance to get insights about how it got information from the variables. Also, I will build a simple tree to find the most obvious user segments
and see if they agree with RF partial dependence plots.
Firstly, "Converted" should really be a factor here as well as new_user. So let's change them:

```{r , message=FALSE, warning=FALSE,echo=TRUE}
data$converted = as.factor(data$converted) # let's make the class a factor
data$new_user = as.factor(data$new_user) #also this a factor
levels(data$country)[levels(data$country)=="Germany"]="DE" # Shorter name, easier to plot.

```

Create test/training set with a standard 66% split (if the data were too small, I would cross-validate) and then build the forest with standard values for the 3 most important parameters (100 trees, trees as large as possible, 3 random variables selected at each split).



```{r , message=FALSE, warning=FALSE,echo=TRUE}
train_sample = sample(nrow(data), size = nrow(data)*0.66)
train_data = data[train_sample,]
test_data = data[-train_sample,]

rf = randomForest(y=train_data$converted, x = train_data[, -ncol(train_data)],
                  ytest = test_data$converted, xtest = test_data[, -ncol(test_data)],
                  ntree = 100, mtry = 3, keep.forest = TRUE)
rf
```


So, OOB error and test error are pretty similar: 1.5% and 1.4%. We are confident we are not overfitting.
Error is pretty low. However, we started from a 97% accuracy (that's the case if we classified everything
as "non converted"). So, 98.5% is good, but nothing shocking. Indeed, 30% of conversions are predicted
as "non conversion".
If we cared about the very best possible accuracy or specifically minimizing false positive/false negative,
we would also use ROCR and find the best cut-off point. Since in this case that doesn't appear to be
particularly relevant, we are fine with the default 0.5 cutoff value used internally by the random forest to
make the prediction.

 Let's check the variable inportance:
 
```{r , message=FALSE, warning=FALSE,echo=TRUE}
varImpPlot(rf,type=2)

```
Total pages visited is the most important one, by far. Unfortunately, it is probably the least "actionable".
People visit many pages cause they already want to buy. Also, in order to buy you have to click on
multiple pages.
Let's rebuild the RF without that variable. Since classes are heavily unbalanced and we don't have that
very powerful variable anymore, let's change the weight a bit, just to make sure we will get something
classified as 1.




```{r , message=FALSE, warning=FALSE,echo=TRUE}
rf = randomForest(y=train_data$converted, x = train_data[, -c(5, ncol(train_data))],
ytest = test_data$converted, xtest = test_data[, -c(5, ncol(train_data))],
ntree = 100, mtry = 3, keep.forest = TRUE, classwt = c(0.7,0.3))
rf

```

Our accuracy went down but the model is still good enough to give us insights.

Let's recheck the variable importance:

```{r , message=FALSE, warning=FALSE,echo=TRUE}

```

```{r , message=FALSE, warning=FALSE,echo=TRUE}

varImpPlot(rf,type = 2)
```
```{r , message=FALSE, warning=FALSE,echo=TRUE}

```
Interesting! New user is the most important one. Source doesn't seem to matter at all.
Let's check partial dependence plots for the 4 vars:
```{r , message=FALSE, warning=FALSE,echo=TRUE}
op <- par(mfrow=c(2, 2))
partialPlot(rf, train_data, country, 1)
partialPlot(rf, train_data, age, 1)
partialPlot(rf, train_data, new_user, 1)
partialPlot(rf, train_data, source, 1)
```

In partial dependence plots, we just care about the trend, not the actual y value. So this shows that:
Users with an old account are much better than new users
China is really bad, all other countries are similar with Germany being the best
The site works very well for young people and bad for less young people (>30 yrs old)
Source is irrelevant
Let's now build a simple decision tree and check the 2 or 3 most important segments:

```{r , message=FALSE, warning=FALSE,echo=TRUE}
tree = rpart(data$converted ~ ., data[, -c(5,ncol(data))],
control = rpart.control(maxdepth = 3),
parms = list(prior = c(0.7, 0.3)))
tree

```

Some conclusions and suggestions:

1. The site is working very well for young users. Definitely let's tell marketing to advertise and use marketing channel which are more likely to reach young people.

2. The site is working very well for Germany in terms of conversion. But the summary showed that
there are few Germans coming to the site: way less than UK, despite a larger population. Again,marketing should get more Germans. Big opportunity.

3. Users with old accounts do much better. Targeted emails with offers to bring them back to the site could be a good idea to try.

4. Something is wrong with the Chinese version of the site. It is either poorly translated, doesn't fit the local culture, some payment issue or maybe it is just in English! Given how many users are based in China, fixing this should be a top priority. Huge opportunity.

5. Maybe go through the UI and figure out why older users perform so poorly? From 30 y/o conversion clearly starts dropping.

6. If I know someone has visited many pages, but hasn't converted, she almost surely has high
purchase intent. I could email her targeted offers or sending her reminders. Overall, these are probably the easiest users to make convert.












